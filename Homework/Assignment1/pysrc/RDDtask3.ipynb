{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark import SparkContext\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/liangsiqi/Documents/Dataset/yelp_dataset/\"\n",
    "user_file = \"user.json\"\n",
    "review_file = \"review.json\"\n",
    "business_file = \"business.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    sc = SparkContext()\n",
    "    reviewRDD = sc.textFile(path+review_file).map(json.loads)\n",
    "    businessRDD = sc.textFile(path+business_file).map(json.loads)\n",
    "\n",
    "    business_state_kvRDD = businessRDD.map(lambda x: [x['business_id'],x['state']])\n",
    "    business_id_star_kvRDD = reviewRDD.map(lambda x: [x['business_id'],x['stars']])\n",
    "    business_id_star_combine = business_id_star_kvRDD.combineByKey((lambda x: (x,1)),  # ceateCombiner\n",
    "                                (lambda x,value: (x[0] + value, x[1] + 1)),  # mergeValue\n",
    "                                (lambda x,y: (x[0] + y[0], x[1] + y[1])))\n",
    "    interm_state_stars_cnt_combine = business_id_star_combine.join(business_state_kvRDD).map(lambda x: (x[1][1],x[1][0]))\n",
    "    interm_state_stars_cnt_combine.persist()\n",
    "    interm_state_stars_cnt = interm_state_stars_cnt_combine.combineByKey((lambda x: (x,1)),  # ceateCombiner\n",
    "                                        (lambda c,value: ((c[0][0] + value[0], c[0][1] + value[1]), c[1]+1)),  # mergeValue\n",
    "                                        (lambda x,y: ((x[0][0] + y[0][0], x[0][1] + y[0][1]), x[1] + y[1])))\n",
    "    avg_state = interm_state_stars_cnt.map(lambda x: [x[0], x[1][0][0] / x[1][0][1]]).sortBy(lambda x: (-x[1],x[0]))\n",
    "    interm_state_stars_cnt_combine.unpersist()\n",
    "    result = avg_state.collect()\n",
    "    sc.stop()\n",
    "    return result\n",
    "\n",
    "def run2():\n",
    "    sc = SparkContext()\n",
    "    reviewRDD = sc.textFile(path+review_file).map(json.loads)\n",
    "    businessRDD = sc.textFile(path+business_file).map(json.loads)\n",
    "\n",
    "    business_state_kvRDD = businessRDD.map(lambda x: [x['business_id'],x['state']])\n",
    "    business_id_star_kvRDD = reviewRDD.map(lambda x: [x['business_id'],x['stars']])\n",
    "    business_id_star_combine = business_id_star_kvRDD.combineByKey((lambda x: (x,1)),  # ceateCombiner\n",
    "                                (lambda x,value: (x[0] + value, x[1] + 1)),  # mergeValue\n",
    "                                (lambda x,y: (x[0] + y[0], x[1] + y[1])))\n",
    "    interm_state_stars_cnt_combine = business_id_star_combine.join(business_state_kvRDD).map(lambda x: (x[1][1],x[1][0]))\n",
    "    interm_state_stars_cnt = interm_state_stars_cnt_combine.combineByKey((lambda x: (x,1)),  # ceateCombiner\n",
    "                                        (lambda c,value: ((c[0][0] + value[0], c[0][1] + value[1]), c[1]+1)),  # mergeValue\n",
    "                                        (lambda x,y: ((x[0][0] + y[0][0], x[0][1] + y[0][1]), x[1] + y[1])))\n",
    "    avg_state = interm_state_stars_cnt.map(lambda x: [x[0], x[1][0][0] / x[1][0][1]]).sortBy(lambda x: (-x[1],x[0]))\n",
    "    result = avg_state.collect()\n",
    "    sc.stop()\n",
    "    return result\n",
    "\n",
    "def run3():\n",
    "    sc = SparkContext()\n",
    "    reviewRDD = sc.textFile(path+review_file).map(json.loads)\n",
    "    businessRDD = sc.textFile(path+business_file).map(json.loads)\n",
    "\n",
    "    business_state_kvRDD = businessRDD.map(lambda x: [x['business_id'],x['state']])\n",
    "    business_id_star_kvRDD = reviewRDD.map(lambda x: [x['business_id'],x['stars']])\n",
    "    business_id_star_combine = business_id_star_kvRDD.combineByKey((lambda x: (x,1)),  # ceateCombiner\n",
    "                                (lambda x,value: (x[0] + value, x[1] + 1)),  # mergeValue\n",
    "                                (lambda x,y: (x[0] + y[0], x[1] + y[1])))\n",
    "    interm_state_stars_cnt_combine = business_id_star_combine.join(business_state_kvRDD).map(lambda x: (x[1][1],x[1][0]))\n",
    "    interm_state_stars_cnt_combine.persist()\n",
    "    interm_state_stars_cnt = interm_state_stars_cnt_combine.combineByKey((lambda x: (x,1)),  # ceateCombiner\n",
    "                                        (lambda c,value: ((c[0][0] + value[0], c[0][1] + value[1]), c[1]+1)),  # mergeValue\n",
    "                                        (lambda x,y: ((x[0][0] + y[0][0], x[0][1] + y[0][1]), x[1] + y[1])))\n",
    "    avg_state = interm_state_stars_cnt.map(lambda x: [x[0], x[1][0][0] / x[1][0][1]]).sortBy(lambda x: (-x[1],x[0]))\n",
    "    result = avg_state.collect()\n",
    "    interm_state_stars_cnt_combine.unpersist()\n",
    "    sc.stop()\n",
    "    return result\n",
    "\n",
    "def run4():\n",
    "    sc = SparkContext()\n",
    "    reviewRDD = sc.textFile(path+review_file).map(json.loads)\n",
    "    businessRDD = sc.textFile(path+business_file).map(json.loads)\n",
    "    business_state_kvRDD = businessRDD.map(lambda x: [x['business_id'],x['state']])\n",
    "    business_id_star_kvRDD = reviewRDD.map(lambda x: [x['business_id'],x['stars']])\n",
    "    join_state_stars = business_id_star_kvRDD.join(business_state_kvRDD).map(lambda x: [x[1][1],x[1][0]])\n",
    "    state_star_combine = join_state_stars.combineByKey((lambda x: (x,1)),  # ceateCombiner\n",
    "                                (lambda x,value: (x[0] + value, x[1] + 1)),  # mergeValue\n",
    "                                (lambda x,y: (x[0] + y[0], x[1] + y[1])))\n",
    "    avg_state = state_star_combine.map(lambda x: [x[0], x[1][0]/x[1][1]]).sortBy(lambda x: (-x[1],x[0]))\n",
    "    result = avg_state.collect()\n",
    "    sc.stop()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run():\n",
      "24.8 s ± 101 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "run2():\n",
      "24.3 s ± 183 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "run3():\n",
      "24.6 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "run4():\n",
      "26.3 s ± 170 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(\"run():\")\n",
    "%timeit run()\n",
    "\n",
    "print(\"\\nrun2():\")\n",
    "%timeit run2()\n",
    "\n",
    "print(\"\\nrun3():\")\n",
    "%timeit run3()\n",
    "\n",
    "print(\"\\nrun4():\")\n",
    "%timeit run4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "kv1 = sc.parallelize([('a',1),\n",
    "                      ('b',2),\n",
    "                      ('c',3),\n",
    "                      ('c',4),\n",
    "                      ('d',5),\n",
    "                      ('d',6),\n",
    "                      ('a',7),\n",
    "                      ('e',8)])\n",
    "kv2 = sc.parallelize([('a','ca'),\n",
    "                      ('b','ca'),\n",
    "                      ('c','ny'),\n",
    "                      ('d','fl'),\n",
    "                      ('e','ny')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', (2, 'ca')),\n",
       " ('d', (5, 'fl')),\n",
       " ('d', (6, 'fl')),\n",
       " ('a', (1, 'ca')),\n",
       " ('a', (7, 'ca')),\n",
       " ('e', (8, 'ny')),\n",
       " ('c', (3, 'ny')),\n",
       " ('c', (4, 'ny'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv1.join(kv2).collect()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultA = run2()\n",
    "\n",
    "with open(\"task3A.txt\", \"w\") as outA:\n",
    "    outA.write(\"state,stars\\n\")\n",
    "    for iterm in resultA:\n",
    "        outA.write(\"%s,%.3f\\n\" % (iterm[0], iterm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN\n",
      "NJ\n",
      "VT\n",
      "XWY\n",
      "XGL\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(resultA[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methd 1:\n",
      "TN\n",
      "NJ\n",
      "VT\n",
      "XWY\n",
      "XGL\n",
      "Methd 2:\n",
      "TN\n",
      "NJ\n",
      "VT\n",
      "XWY\n",
      "XGL\n",
      "Method 1: 0.5144200325\n",
      "Method 2: 0.0914618969\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()\n",
    "reviewRDD = sc.textFile(path+review_file).map(json.loads)\n",
    "businessRDD = sc.textFile(path+business_file).map(json.loads)\n",
    "\n",
    "business_state_kvRDD = businessRDD.map(lambda x: [x['business_id'], x['state']])\n",
    "business_id_star_kvRDD = reviewRDD.map(lambda x: [x['business_id'], x['stars']])\n",
    "business_id_star_combine = business_id_star_kvRDD.combineByKey((lambda x: (x, 1)),  # ceateCombiner\n",
    "                                                               (lambda x, value: (x[0] + value, x[1] + 1)),  # mergeValue\n",
    "                                                               (lambda x, y: (x[0] + y[0], x[1] + y[1])))\n",
    "\n",
    "interm_state_stars_cnt_combine = business_id_star_combine.join(business_state_kvRDD).map(lambda x: (x[1][1], x[1][0]))\n",
    "\n",
    "interm_state_stars_cnt = interm_state_stars_cnt_combine.combineByKey((lambda x: (x, 1)),  # ceateCombiner\n",
    "                                                                     (lambda c, value: ((c[0][0] + value[0], c[0][1] + value[1]),\n",
    "                                                                                        c[1] + 1)),  # mergeValue\n",
    "                                                                     (lambda x, y: ((x[0][0] + y[0][0], x[0][1] + y[0][1]),\n",
    "                                                                                    x[1] + y[1])))\n",
    "avg_state = interm_state_stars_cnt.map(lambda x: [x[0], x[1][0][0] / x[1][0][1]]).sortBy(lambda x: (-x[1], x[0]))\n",
    "print(\"Methd 1:\")\n",
    "start1 = time()\n",
    "resultA = avg_state.collect()\n",
    "for i in range(5):\n",
    "    print(resultA[i][0])\n",
    "end1 = time()\n",
    "m1 = end1 - start1\n",
    "\n",
    "print(\"Methd 2:\")\n",
    "start2 = time()\n",
    "resultB = avg_state.take(5)\n",
    "for i in range(5):\n",
    "    print(resultB[i][0])\n",
    "end2 = time()\n",
    "m2 = end2 - start2\n",
    "\n",
    "sc.stop()\n",
    "\n",
    "print(\"Method 1: %.10f\" % m1)\n",
    "print(\"Method 2: %.10f\" % m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:inf553]",
   "language": "python",
   "name": "conda-env-inf553-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
