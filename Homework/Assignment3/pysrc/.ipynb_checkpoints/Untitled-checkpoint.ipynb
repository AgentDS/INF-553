{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "from numpy.random import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data example:\n",
      "user_id, business_id, stars\n",
      "['vxR_YV0atFxIxfOnF9uHjQ', 'gTw6PENNGl68ZPUpYWP50A', '5.0']\n",
      "['o0p-iTC5yTBV5Yab_7es4g', 'iAuOpYDfOTuzQ6OPpEiGwA', '4.0']\n",
      "['-qj9ouN0bzMXz1vfEslG-A', '5j7BnXXvlS69uLVHrY9Upw', '2.0']\n",
      "\n",
      "Total number in '../data/yelp_train.csv': 455854\n",
      "User id numbers: 11270\n",
      "Business id numbers: 24732\n",
      "Min value of rating: 1.0\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/yelp_train.csv\"\n",
    "minPartition = 3\n",
    "raw_data = sc.textFile(input_file) #(input_file, minPartition)\n",
    "header = raw_data.first()\n",
    "clean_data = raw_data.filter(lambda x: x != header).mapPartitions(lambda x: csv.reader(x))\n",
    "\n",
    "print(\"Raw data example:\")\n",
    "print(header)\n",
    "for line in clean_data.take(3):\n",
    "    print(line)\n",
    "print(\"\\nTotal number in '%s': %d\" % (input_file, clean_data.count()))\n",
    "\n",
    "user_ids = clean_data.map(lambda x: x[0]).distinct().collect()\n",
    "business_ids = clean_data.map(lambda x: x[1]).distinct().collect()\n",
    "rating = clean_data.map(lambda x: float(x[2]))\n",
    "print(\"User id numbers: %d\" % len(user_ids))\n",
    "print(\"Business id numbers: %d\" % len(business_ids))\n",
    "print(\"Min value of rating: %.1f\" % rating.min())\n",
    "\n",
    "uid2idx = dict()\n",
    "bid2idx = dict()\n",
    "idx2bid = dict()\n",
    "for idx,uid in enumerate(user_ids,0):\n",
    "    uid2idx[uid] = idx\n",
    "\n",
    "for idx,bid in enumerate(business_ids,0):\n",
    "    bid2idx[bid] = idx\n",
    "    idx2bid[idx] = bid\n",
    "\n",
    "def id_to_index(iteration,order=\"u,b\"):\n",
    "    iteration = list(iteration)\n",
    "    for review in iteration:\n",
    "        uidx = uid2idx[review[0]]\n",
    "        bidx = bid2idx[review[1]]\n",
    "        if order == \"u,b\":\n",
    "            yield [uidx,[bidx]]\n",
    "        elif order == \"b,u\":\n",
    "            yield [bidx,[uidx]]\n",
    "\n",
    "def sort_idxs(iteration):\n",
    "    iteration = list(iteration)\n",
    "    for line in iteration:\n",
    "        yield [line[0],sorted(line[1])]\n",
    "        \n",
    "# convert to [uidx,[bidx1, bidx2, ...]], [bidx1, bidx2, ...] is sorted\n",
    "rows = clean_data.mapPartitions(lambda iters: id_to_index(iters,\"u,b\")).reduceByKey(lambda a,b: a+b).mapPartitions(lambda iters: sort_idxs(iters))\n",
    "rows.persist() # TODO???\n",
    "# convert to [bidx,[uidx1, uidx2, ...]] , [uidx1, uidx2, ...] is sorted\n",
    "columns = clean_data.mapPartitions(lambda iters: id_to_index(iters,\"b,u\")).reduceByKey(lambda a,b: a+b).mapPartitions(lambda iters: sort_idxs(iters))\n",
    "columns.persist() # TODO???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "user_cnt = len(user_ids)\n",
    "business_cnt = len(business_ids)\n",
    "hash_num = 100\n",
    "a_values = []\n",
    "b_values = []\n",
    "for i in range(hash_num):\n",
    "    a_r = random.randint(1,business_cnt)\n",
    "    while a_r in a_values:\n",
    "        a_r = random.randint(1,business_cnt)\n",
    "    a_values.append(a_r)\n",
    "    b_values.append(random.randint(1,business_cnt))\n",
    "\n",
    "    \n",
    "    \n",
    "# [uidx, [h1(uidx), h2(uidx), ...]]\n",
    "def cal_hash(iters,a_list,b_list,hash_num):\n",
    "    iters = list(iters)\n",
    "    for x in iters:\n",
    "        yield (x,[(x*a + b) % hash_num for a,b in zip(a_list,b_list)])\n",
    "\n",
    "# {uidx1: [h1(uidx1), h2(uidx1), ...], \n",
    "#  uidx2: [h1(uidx2), h2(uidx2), ...],\n",
    "#  ...}\n",
    "hash_values = rows.keys().mapPartitions(lambda iters: cal_hash(iters, a_values,b_values,hash_num)).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_values_bc = sc.broadcast(hash_values)\n",
    "def min_hash(iters,hash_bc,hash_num):\n",
    "    iters = list(iters)\n",
    "    for business_col in iters:\n",
    "        bidx = business_col[0]\n",
    "        uidxs = business_col[1]\n",
    "        tmp_signature_col = [[] for i in range(hash_num)]\n",
    "        for uidx in uidxs:\n",
    "            hash_col_u = hash_bc.value[uidx]\n",
    "            for i in range(hash_num):\n",
    "                tmp_signature_col[i].append(hash_col_u[i])\n",
    "        signature_col = [min(i) for i in tmp_signature_col]  # a little bit faster than using list(map(min,tmp_signature_col))\n",
    "        yield (bidx, signature_col)\n",
    "\n",
    "# (bidx, [sig1,sig2, ...])\n",
    "signature_mat = columns.mapPartitions(lambda iteration: min_hash(iteration, hash_values_bc,hash_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.4 ms ± 651 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "23.8 ms ± 428 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "mat = rand(hash_num,business_cnt).tolist()\n",
    "\n",
    "%timeit list(map(min,mat))\n",
    "%timeit [min(i) for i in mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [1,2,3,4,5,8,10,20,30,60,120]\n",
    "b = [int(120/i) for i in r]\n",
    "v = [(1/bb)**(1/rr) for bb,rr in zip(b,r)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.008333333333333333,\n",
       " 0.12909944487358055,\n",
       " 0.2924017738212866,\n",
       " 0.42728700639623407,\n",
       " 0.5296119205244061,\n",
       " 0.7128343062413697,\n",
       " 0.7799771419043033,\n",
       " 0.914307826761828,\n",
       " 0.9548416039104165,\n",
       " 0.9885140203528962,\n",
       " 1.0]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:inf553]",
   "language": "python",
   "name": "conda-env-inf553-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
